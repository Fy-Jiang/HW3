{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2bf0902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jieba\n",
      "  Using cached jieba-0.42.1.tar.gz (19.2 MB)\n",
      "Building wheels for collected packages: jieba\n",
      "  Building wheel for jieba (setup.py): started\n",
      "  Building wheel for jieba (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba: filename=jieba-0.42.1-py3-none-any.whl size=19314477 sha256=588714df918e3be290b359a83bab0e40f4376b9d58abd7fcd77a928aabdd78b9\n",
      "  Stored in directory: c:\\users\\fyj19\\appdata\\local\\pip\\cache\\wheels\\ca\\38\\d8\\dfdfe73bec1d12026b30cb7ce8da650f3f0ea2cf155ea018ae\n",
      "Successfully built jieba\n",
      "Installing collected packages: jieba\n",
      "Successfully installed jieba-0.42.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8fa4ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split    #分割資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd14a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutval(df):\n",
    "    topcut = []\n",
    "    for d in df['簡介']:\n",
    "        top = jieba.analyse.extract_tags(d,topK=2)\n",
    "        topcut.append(top)\n",
    "\n",
    "    typecut = []\n",
    "    for d in df['類型']:\n",
    "        ch =re.compile(\"[\\u4e00-\\u9fa5]\")\n",
    "        seg_word =  \"\".join(ch.findall(d))\n",
    "        top = jieba.lcut(seg_word)\n",
    "        typecut.append(top)\n",
    "\n",
    "    namecut = []\n",
    "    for d in df['中文名稱']:\n",
    "        ch =re.compile(\"[\\u4e00-\\u9fa5]\")\n",
    "        name =  \"\".join(ch.findall(d))\n",
    "        namecut.append(name)\n",
    "\n",
    "    data = { 'type':typecut ,'name':namecut,'article':topcut}\n",
    "    df1 = pd.DataFrame(data)\n",
    "\n",
    "    df1['type'] = df1['type'].apply(lambda x :  str(x)[1:-2].replace(\"'\",\"\").replace(\",\",\"\"))\n",
    "    df1['article'] = df1['article'].apply(lambda x :  str(x)[1:-2].replace(\"'\",\"\").replace(\",\",\"\"))\n",
    "    df1['key'] = df1['name'].astype(str)+' '+df1['type'].astype(str)+' '+df1['article'].astype(str)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac71f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(df):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(df['key'])\n",
    "    tfidf = TfidfTransformer() \n",
    "    tf=tfidf.fit_transform(X)\n",
    "    word = vectorizer.get_feature_names() #詞袋 \n",
    "    \n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26731ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X,Y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y['type'].str[0:2], test_size=0.07659)\n",
    "    clf=KNeighborsClassifier(n_neighbors=51)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)    # 預測模型 \n",
    "    y_test=y_test.values\n",
    "\n",
    "    print(\"精準度：\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ae0f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\fyj19\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.036 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精準度： 0.726\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df = df.drop(labels=['Unnamed: 0'],axis='columns')\n",
    "df1 = cutval(df) \n",
    "tf = count(df1)\n",
    "knn(tf,df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd72e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
